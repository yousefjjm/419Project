{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5df-LhzMGzZ7"
      },
      "outputs": [],
      "source": [
        "#Importing the Database from google collab files tab\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('IMDB Dataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj7ZBElaHUSa",
        "outputId": "7e9a7b8c-043f-4449-8fae-fed9eb88c95a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/naitor/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/naitor/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Data Curation Code\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Use the filename with which you uploaded the file\n",
        "#df = pd.read_csv('IMDB Dataset.csv')\n",
        "\n",
        "df['review'] = df['review'].str.lower()\n",
        "\n",
        "# Regular expression pattern for matching all punctuation\n",
        "punctuation_pattern = r'[^\\w\\s]'\n",
        "\n",
        "# Replace punctuation with an empty string\n",
        "df['review'] = df['review'].str.replace(punctuation_pattern, '', regex=True)\n",
        "\n",
        "# Download the required NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example DataFrame\n",
        "# df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text)\n",
        "\n",
        "# Apply tokenization to each row in the DataFrame\n",
        "df['tokenized'] = df['review'].apply(tokenize_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Example DataFrame\n",
        "\n",
        "# Function to remove stop words from a list of tokens\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if not word in stop_words ]\n",
        "\n",
        "# Assuming 'tokenized_text' is the column with tokenized reviews\n",
        "df['text_without_stopwords'] = df['tokenized'].apply(remove_stopwords)\n",
        "\n",
        "# Now 'text_without_stopwords' will contain the text data without stop words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Join the tokens back into strings\n",
        "df['processed_text'] = df['text_without_stopwords'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "\n",
        "df = df[df['processed_text'].notna() & (df['processed_text'] != '')]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eJCNE6OLU3B"
      },
      "source": [
        "**Bag of Words**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "the following code using the CounterVectorizer From sklearn to emplement the Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJKl0Tc6LcVU",
        "outputId": "198b1112-26e9-4008-c422-415794193f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BoW time is 3.4287869930267334 seconds\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time() # Start Time\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "# Fit and transform the processed text data\n",
        "bow_features = vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "end_time = time.time() # Stop Time\n",
        "\n",
        "T_Time_BoW = end_time - start_time # Total time\n",
        "\n",
        "print(f\"The BoW time is {T_Time_BoW} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Otq2TJTmVU"
      },
      "source": [
        "**N_Grams**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "the following code using the CounterVectorizer From sklearn, the code is comparing the bi grams and the tri grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T9CTjGJTlmT",
        "outputId": "dcc632cf-862f-4608-8394-0d9152161caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Bi_Grams time is 15.770915031433105 seconds\n",
            "The Tri_Grams time is 24.647441148757935 seconds\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import time\n",
        "\n",
        "#=====================================================================================================\n",
        "\n",
        "# Bi-Grams\n",
        "\n",
        "start_time = time.time() # Start Time\n",
        "\n",
        "bi_vectorizer = CountVectorizer(ngram_range=(2,2)) # Only Bigrams\n",
        "bi_features = bi_vectorizer.fit_transform(df['processed_text'])   # Transform\n",
        "\n",
        "feature_name = bi_vectorizer.get_feature_names_out() # Exctracting the feature names\n",
        "\n",
        "#print(feature_name)\n",
        "\n",
        "#print(X_bi.toarray())\n",
        "\n",
        "\n",
        "\n",
        "end_time = time.time() # Stop Time\n",
        "\n",
        "T_Time_bi = end_time - start_time # Total time\n",
        "\n",
        "print(f\"The Bi_Grams time is {T_Time_bi} seconds\")\n",
        "\n",
        "#=====================================================================================================\n",
        "\n",
        "#Tri-Grams\n",
        "\n",
        "\n",
        "start_time = time.time() # Start Time\n",
        "\n",
        "tri_vectorizer = CountVectorizer(ngram_range=(3,3)) # Only trigrams\n",
        "tri_features = tri_vectorizer.fit_transform(df['processed_text'])   # Transform\n",
        "\n",
        "feature_name_tri = tri_vectorizer.get_feature_names_out() # Exctracting the feature names\n",
        "\n",
        "#print(feature_name_tri)\n",
        "#print(X_tri.toarray())\n",
        "\n",
        "\n",
        "\n",
        "end_time = time.time() # Stop Time\n",
        "\n",
        "T_Time_tri = end_time - start_time # Total time\n",
        "\n",
        "print(f\"The Tri_Grams time is {T_Time_tri} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSQ1YkbQcy8p"
      },
      "source": [
        "**TF-IDF**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "the following code using the TfidfVectorizer From sklearn to emplement TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BfH6F-zac-I8"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import time\n",
        "\n",
        "#===============================================================================\n",
        "#TF-IDF\n",
        "\n",
        "start_time = time.time() # Start Time\n",
        "\n",
        "# Initialize a TfidfVectorizer object\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Assuming 'processed_text' is your column with preprocessed text data\n",
        "tfidf_features = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
        "\n",
        "end_time = time.time() # Stop Time\n",
        "\n",
        "T_Time_tfidf = end_time - start_time # Total time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxRh6ZFJWw6n"
      },
      "source": [
        "**Learning The Model**\n",
        "\n",
        "---\n",
        "\n",
        "In this part of the code we will be applying Models on the vectorizers we used above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2mHSPBkRJGl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n",
        "# Dictionary of models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "    'Ridge classifier': RidgeClassifier(),\n",
        "    'SGDClassifier': SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AppuOi676_VH",
        "outputId": "4a7bf9b4-b82e-44d8-9614-1686f563478e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/2TBHHD/EE/term 231/ee491/Project/Code3/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Elapsed Time: 6.15 seconds\n",
            "BoW Accuracy: 0.88465\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.88      0.88      9989\n",
            "    positive       0.88      0.89      0.89     10011\n",
            "\n",
            "    accuracy                           0.88     20000\n",
            "   macro avg       0.88      0.88      0.88     20000\n",
            "weighted avg       0.88      0.88      0.88     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Naive Bayes\n",
            "Elapsed Time: 0.06 seconds\n",
            "BoW Accuracy: 0.86035\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.87      0.86      9989\n",
            "    positive       0.87      0.85      0.86     10011\n",
            "\n",
            "    accuracy                           0.86     20000\n",
            "   macro avg       0.86      0.86      0.86     20000\n",
            "weighted avg       0.86      0.86      0.86     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Random Forest\n",
            "Elapsed Time: 135.98 seconds\n",
            "BoW Accuracy: 0.8577\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.86      0.86      9989\n",
            "    positive       0.86      0.86      0.86     10011\n",
            "\n",
            "    accuracy                           0.86     20000\n",
            "   macro avg       0.86      0.86      0.86     20000\n",
            "weighted avg       0.86      0.86      0.86     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Ridge classifier\n",
            "Elapsed Time: 38.18 seconds\n",
            "BoW Accuracy: 0.8033\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.81      0.80      0.80      9989\n",
            "    positive       0.80      0.81      0.80     10011\n",
            "\n",
            "    accuracy                           0.80     20000\n",
            "   macro avg       0.80      0.80      0.80     20000\n",
            "weighted avg       0.80      0.80      0.80     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: SGDClassifier\n",
            "Elapsed Time: 0.35 seconds\n",
            "BoW Accuracy: 0.8748\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.87      0.87      9989\n",
            "    positive       0.87      0.88      0.88     10011\n",
            "\n",
            "    accuracy                           0.87     20000\n",
            "   macro avg       0.87      0.87      0.87     20000\n",
            "weighted avg       0.87      0.87      0.87     20000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#=====================================================================================================\n",
        "\n",
        "\n",
        "\n",
        "#Bag of Words Logistric Regression\n",
        "\n",
        "# Split the data\n",
        "X_BoW_train, X_BoW_test, y_BoW_train, y_BoW_test = train_test_split(bow_features, df['sentiment'], test_size=0.4, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "# Train the logistic regression model\n",
        "BoW_log_reg_model = LogisticRegression()\n",
        "BoW_log_reg_model.fit(X_BoW_train, y_BoW_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_BoW_pred = BoW_log_reg_model.predict(X_BoW_test)\n",
        "BoW_accuracy = accuracy_score(y_BoW_test, y_BoW_pred)\n",
        "BoW_report = classification_report(y_BoW_test, y_BoW_pred)\n",
        "\n",
        "\n",
        "print(f\"The BoW time is {T_Time_BoW} seconds\")\n",
        "print(\"bow Accuracy:\", BoW_accuracy)\n",
        "print(\"Classification Report:\\n\", BoW_report)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Loop through models\n",
        "for model_name, model in models.items():\n",
        "    start_time = time.time()  # Start time\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_BoW_train, y_BoW_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_BoW_pred = model.predict(X_BoW_test)\n",
        "\n",
        "    end_time = time.time()  # End time\n",
        "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
        "\n",
        "    # Evaluate the model\n",
        "    BoW_accuracy = accuracy_score(y_BoW_test, y_BoW_pred)\n",
        "    BoW_report = classification_report(y_BoW_test, y_BoW_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "    print(\"BoW Accuracy:\", BoW_accuracy)\n",
        "    print(\"Classification Report:\\n\", BoW_report)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDHsxPP8Vapf",
        "outputId": "faec0baf-4306-4203-b451-1b8fab592b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Elapsed Time: 29.77 seconds\n",
            "TF-IDF Accuracy: 0.86\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.83      0.86      9989\n",
            "    positive       0.84      0.89      0.86     10011\n",
            "\n",
            "    accuracy                           0.86     20000\n",
            "   macro avg       0.86      0.86      0.86     20000\n",
            "weighted avg       0.86      0.86      0.86     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Naive Bayes\n",
            "Elapsed Time: 0.18 seconds\n",
            "TF-IDF Accuracy: 0.8793\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.91      0.88      9989\n",
            "    positive       0.91      0.85      0.88     10011\n",
            "\n",
            "    accuracy                           0.88     20000\n",
            "   macro avg       0.88      0.88      0.88     20000\n",
            "weighted avg       0.88      0.88      0.88     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Ridge classifier\n",
            "Elapsed Time: 12.86 seconds\n",
            "TF-IDF Accuracy: 0.8562\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.83      0.85      9989\n",
            "    positive       0.84      0.88      0.86     10011\n",
            "\n",
            "    accuracy                           0.86     20000\n",
            "   macro avg       0.86      0.86      0.86     20000\n",
            "weighted avg       0.86      0.86      0.86     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: SGDClassifier\n",
            "Elapsed Time: 0.41 seconds\n",
            "TF-IDF Accuracy: 0.8595\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.83      0.86      9989\n",
            "    positive       0.84      0.89      0.86     10011\n",
            "\n",
            "    accuracy                           0.86     20000\n",
            "   macro avg       0.86      0.86      0.86     20000\n",
            "weighted avg       0.86      0.86      0.86     20000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#=====================================================================================================\n",
        "\n",
        "#Bi-Grams Logistric Regression\n",
        "\n",
        "# Split the data\n",
        "X_bi_train, X_bi_test, y_bi_train, y_bi_test = train_test_split(bi_features, df['sentiment'], test_size=0.4, random_state=42)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Train the logistic regression model\n",
        "bi_log_reg_model = LogisticRegression()\n",
        "bi_log_reg_model.fit(X_bi_train, y_bi_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_bi_pred = bi_log_reg_model.predict(X_bi_test)\n",
        "bi_accuracy = accuracy_score(y_bi_test, y_bi_pred)\n",
        "bi_report = classification_report(y_bi_test, y_bi_pred)\n",
        "\n",
        "\n",
        "print(f\"The bi-gram time is {T_Time_bi} seconds\")\n",
        "print(\"bi-gram Accuracy:\", bi_accuracy)\n",
        "print(\"Classification Report:\\n\", bi_report)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Loop through models\n",
        "for model_name, model in models.items():\n",
        "    start_time = time.time()  # Start time\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_bi_train, y_bi_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_bi_pred = model.predict(X_bi_test)\n",
        "\n",
        "    end_time = time.time()  # End time\n",
        "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
        "\n",
        "    # Evaluate the model\n",
        "    bi_accuracy = accuracy_score(y_bi_test, y_bi_pred)\n",
        "    bi_report = classification_report(y_bi_test, y_bi_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "    print(\"TF-IDF Accuracy:\", bi_accuracy)\n",
        "    print(\"Classification Report:\\n\", bi_report)\n",
        "    print(\"-\" * 50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOfp94ERWGeZ",
        "outputId": "acb68d4f-cc53-4174-97cd-6411757598b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Elapsed Time: 27.91 seconds\n",
            "TRI-Grams Accuracy: 0.7201\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.54      0.66      9989\n",
            "    positive       0.66      0.90      0.76     10011\n",
            "\n",
            "    accuracy                           0.72     20000\n",
            "   macro avg       0.75      0.72      0.71     20000\n",
            "weighted avg       0.75      0.72      0.71     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Naive Bayes\n",
            "Elapsed Time: 0.28 seconds\n",
            "TRI-Grams Accuracy: 0.77535\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.86      0.79      9989\n",
            "    positive       0.83      0.69      0.75     10011\n",
            "\n",
            "    accuracy                           0.78     20000\n",
            "   macro avg       0.78      0.78      0.77     20000\n",
            "weighted avg       0.78      0.78      0.77     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Ridge classifier\n",
            "Elapsed Time: 12.27 seconds\n",
            "TRI-Grams Accuracy: 0.7252\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.55      0.67      9989\n",
            "    positive       0.67      0.90      0.77     10011\n",
            "\n",
            "    accuracy                           0.73     20000\n",
            "   macro avg       0.75      0.73      0.72     20000\n",
            "weighted avg       0.75      0.73      0.72     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: SGDClassifier\n",
            "Elapsed Time: 0.49 seconds\n",
            "TRI-Grams Accuracy: 0.7121\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.51      0.64      9989\n",
            "    positive       0.65      0.92      0.76     10011\n",
            "\n",
            "    accuracy                           0.71     20000\n",
            "   macro avg       0.76      0.71      0.70     20000\n",
            "weighted avg       0.76      0.71      0.70     20000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#=====================================================================================================\n",
        "\n",
        "#Tri-Grams Logistric Regression\n",
        "\n",
        "# Split the data\n",
        "X_tri_train, X_tri_test, y_tri_train, y_tri_test = train_test_split(tri_features, df['sentiment'], test_size=0.4, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Train the logistic regression model\n",
        "tri_log_reg_model = LogisticRegression()\n",
        "tri_log_reg_model.fit(X_tri_train, y_tri_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_tri_pred = tri_log_reg_model.predict(X_tri_test)\n",
        "tri_accuracy = accuracy_score(y_tri_test, y_tri_pred)\n",
        "tri_report = classification_report(y_tri_test, y_tri_pred)\n",
        "\n",
        "\n",
        "print(f\"The tri-gram time is {T_Time_tri} seconds\")\n",
        "print(\"tri-gram Accuracy:\", tri_accuracy)\n",
        "print(\"Classification Report:\\n\", tri_report)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Loop through models\n",
        "for model_name, model in models.items():\n",
        "    start_time = time.time()  # Start time\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_tri_train, y_tri_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_tri_pred = model.predict(X_tri_test)\n",
        "\n",
        "    end_time = time.time()  # End time\n",
        "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
        "\n",
        "    # Evaluate the model\n",
        "    tri_accuracy = accuracy_score(y_tri_test, y_tri_pred)\n",
        "    tri_report = classification_report(y_tri_test, y_tri_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "    print(\"TRI-Grams Accuracy:\", tri_accuracy)\n",
        "    print(\"Classification Report:\\n\", tri_report)\n",
        "    print(\"-\" * 50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuSf3YoEblcH",
        "outputId": "b12e8c92-200e-4007-eeee-f9c2448b2a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Logistic Regression\n",
            "Elapsed Time: 4.52 seconds\n",
            "TF-IDF Accuracy: 0.89415\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.88      0.89      9989\n",
            "    positive       0.88      0.91      0.90     10011\n",
            "\n",
            "    accuracy                           0.89     20000\n",
            "   macro avg       0.89      0.89      0.89     20000\n",
            "weighted avg       0.89      0.89      0.89     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Naive Bayes\n",
            "Elapsed Time: 0.06 seconds\n",
            "TF-IDF Accuracy: 0.8665\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.88      0.87      9989\n",
            "    positive       0.88      0.85      0.86     10011\n",
            "\n",
            "    accuracy                           0.87     20000\n",
            "   macro avg       0.87      0.87      0.87     20000\n",
            "weighted avg       0.87      0.87      0.87     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Random Forest\n",
            "Elapsed Time: 118.56 seconds\n",
            "TF-IDF Accuracy: 0.8536\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.86      0.85      9989\n",
            "    positive       0.86      0.85      0.85     10011\n",
            "\n",
            "    accuracy                           0.85     20000\n",
            "   macro avg       0.85      0.85      0.85     20000\n",
            "weighted avg       0.85      0.85      0.85     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Gradient Boosting Classifier\n",
            "Elapsed Time: 247.70 seconds\n",
            "TF-IDF Accuracy: 0.8097\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.75      0.80      9989\n",
            "    positive       0.78      0.87      0.82     10011\n",
            "\n",
            "    accuracy                           0.81     20000\n",
            "   macro avg       0.81      0.81      0.81     20000\n",
            "weighted avg       0.81      0.81      0.81     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: Ridge classifier\n",
            "Elapsed Time: 1.72 seconds\n",
            "TF-IDF Accuracy: 0.8924\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.88      0.89      9989\n",
            "    positive       0.88      0.91      0.89     10011\n",
            "\n",
            "    accuracy                           0.89     20000\n",
            "   macro avg       0.89      0.89      0.89     20000\n",
            "weighted avg       0.89      0.89      0.89     20000\n",
            "\n",
            "--------------------------------------------------\n",
            "Model: SGDClassifier\n",
            "Elapsed Time: 0.18 seconds\n",
            "TF-IDF Accuracy: 0.89465\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.87      0.89      9989\n",
            "    positive       0.88      0.92      0.90     10011\n",
            "\n",
            "    accuracy                           0.89     20000\n",
            "   macro avg       0.90      0.89      0.89     20000\n",
            "weighted avg       0.90      0.89      0.89     20000\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#=====================================================================================================\n",
        "\n",
        "#TF-IDF Logistric Processing\n",
        "\n",
        "\n",
        "# Split the data\n",
        "X_tfidf_train, X_tfidf_test, y_tfidf_train, y_tfidf_test = train_test_split(tfidf_features, df['sentiment'], test_size=0.4, random_state=42)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Train the logistic regression model\n",
        "tfidf_log_reg_model = LogisticRegression()\n",
        "tfidf_log_reg_model.fit(X_tfidf_train, y_tfidf_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_tfidf_pred = tfidf_log_reg_model.predict(X_tfidf_test)\n",
        "tfidf_accuracy = accuracy_score(y_tfidf_test, y_tfidf_pred)\n",
        "tfidf_report = classification_report(y_tfidf_test, y_tfidf_pred)\n",
        "\n",
        "\n",
        "print(f\"The TF-IDF time is {T_Time_tfidf} seconds\")\n",
        "print(\"TF-IDF Accuracy:\", tfidf_accuracy)\n",
        "print(\"Classification Report:\\n\", tfidf_report)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Loop through models\n",
        "for model_name, model in models.items():\n",
        "    start_time = time.time()  # Start time\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_tfidf_train, y_tfidf_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_tfidf_pred = model.predict(X_tfidf_test)\n",
        "\n",
        "    end_time = time.time()  # End time\n",
        "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
        "\n",
        "    # Evaluate the model\n",
        "    tfidf_accuracy = accuracy_score(y_tfidf_test, y_tfidf_pred)\n",
        "    tfidf_report = classification_report(y_tfidf_test, y_tfidf_pred)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "    print(\"TF-IDF Accuracy:\", tfidf_accuracy)\n",
        "    print(\"Classification Report:\\n\", tfidf_report)\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvNlWzDzRJGn",
        "outputId": "5ffca699-4abf-495a-d449-3223e89c3d9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 0.6947976577131054\n",
            "Epoch: 2, Loss: 0.6936485820178744\n",
            "Epoch: 3, Loss: 0.6933641931678676\n",
            "Epoch: 4, Loss: 0.6931701483605783\n",
            "Epoch: 5, Loss: 0.6932853928095177\n",
            "Test Accuracy: 50.22%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Parameters\n",
        "BATCH_SIZE = 512\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "MAX_VOCAB_SIZE = 10_000\n",
        "CSV_FILE_PATH = '/2TBHHD/EE/term 231/ee491/Project/Code3/IMDB Dataset.csv'  # Update with your file path\n",
        "\n",
        "\"\"\"\n",
        "# Read CSV file\n",
        "df = pd.read_csv(CSV_FILE_PATH)\n",
        "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})  # Adjust column names if necessary\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Split data\n",
        "train_data, test_data = train_test_split(df, test_size=0.2)\n",
        "\n",
        "# Tokenizer and Vocabulary\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Adding special tokens to the vocabulary\n",
        "special_tokens = ['<unk>', '<pad>']\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_data['processed_text']), specials=special_tokens, max_tokens=MAX_VOCAB_SIZE)\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "\n",
        "# Process text data function\n",
        "def process_text(text):\n",
        "    return torch.tensor(vocab(tokenizer(text)), dtype=torch.int64)\n",
        "\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "        # Convert 'sentiment' to numerical values\n",
        "        self.dataframe['sentiment'] = self.dataframe['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = process_text(self.dataframe.iloc[idx]['processed_text'])\n",
        "        label = self.dataframe.iloc[idx]['sentiment']\n",
        "        return torch.tensor(label, dtype=torch.float32), text\n",
        "\n",
        "# Ensure you have the collate function defined for padding\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = zip(*batch)\n",
        "    labels = torch.tensor(label_list, dtype=torch.float32)\n",
        "    text_padded = pad_sequence(text_list, padding_value=vocab['<pad>'])\n",
        "    return labels, text_padded\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = IMDBDataset(train_data)\n",
        "test_dataset = IMDBDataset(test_data)\n",
        "\n",
        "\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define the RNN Model\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        output, (hidden, _) = self.rnn(embedded)\n",
        "        return self.fc(hidden.squeeze(0))\n",
        "\n",
        "# Instantiate the model, loss function, and optimizer\n",
        "model = RNNModel(len(vocab), EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(5):  # Number of epochs\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for labels, text in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = loss_function(predictions, labels.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch: {epoch + 1}, Loss: {total_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "total_acc, total_count = 0, 0\n",
        "with torch.no_grad():\n",
        "    for labels, text in test_loader:\n",
        "        predicted_labels = torch.sigmoid(model(text).squeeze(1)) >= 0.5\n",
        "        total_acc += (predicted_labels == labels).sum().item()\n",
        "        total_count += labels.size(0)\n",
        "print(f'Test Accuracy: {(total_acc / total_count) * 100:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}